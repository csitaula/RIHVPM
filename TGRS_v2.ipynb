{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, add, Permute, Conv2D, Add, \\\n",
    "    Concatenate, Multiply, LSTM, Flatten, Activation, SeparableConv2D, average\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "# import tensorflow.keras.layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, Conv2D, add, TimeDistributed, GlobalAveragePooling2D, \\\n",
    "    Dropout, \\\n",
    "    Concatenate, concatenate, \\\n",
    "    Dense, GlobalMaxPooling2D, MaxPooling2D, Lambda, Add, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.densenet import DenseNet201, DenseNet121, DenseNet169\n",
    "from tensorflow.keras.layers import Input, Bidirectional, Conv2D, add, TimeDistributed, GlobalAveragePooling2D, \\\n",
    "    Dropout, \\\n",
    "    Concatenate, concatenate, \\\n",
    "    Dense, GlobalMaxPooling2D, MaxPooling2D, Lambda, Add, Layer, BatchNormalization, ReLU, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import math\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, add, Permute, Conv2D, Add, \\\n",
    "    Concatenate, Multiply, LSTM, Flatten, Activation, SeparableConv2D, average\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Multiply, \\\n",
    "    Permute, Concatenate, \\\n",
    "    Conv2D, Add, Activation, Lambda, add, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "import random\n",
    "import keras_preprocessing.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.19.2 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/scipy-bundle/2020.11/lib/python3.8/site-packages (from tensorflow) (1.19.4)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/protobuf-python/3.14.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12.0 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/flatbuffers-python/1.12/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py~=3.1 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/h5py/3.1.0/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras~=2.6 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/jupyter/1.0.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (3.10.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: mpi4py>=3.0.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/scipy-bundle/2020.11/lib/python3.8/site-packages (from h5py~=3.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/setuptools/57.4.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/10.2.0-11.1.1/openmpi/4.0.5/tensorflow/2.6.0-python-3.8.6/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/10.2.0/python/3.8.6/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock(Layer):\n",
    "\n",
    "    def __init__(self, filters=256, kernel_size=3, dilation_rate=1, **kwargs):\n",
    "        super(ConvBlock, self).__init__(**kwargs)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = dilation_rate\n",
    "\n",
    "        self.net = Sequential([\n",
    "            Conv2D(filters, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate, use_bias=False,\n",
    "                   kernel_initializer='he_normal'),\n",
    "            BatchNormalization(),\n",
    "            ReLU()\n",
    "        ])\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"dilation_rate\": self.dilation_rate,\n",
    "        }\n",
    "\n",
    "\n",
    "def AtrousSpatialPyramidPooling(X):\n",
    "    B, H, W, C = X.shape\n",
    "\n",
    "    # Image Pooling\n",
    "    image_pool = AveragePooling2D(pool_size=(H, W))(X)\n",
    "    image_pool = ConvBlock(kernel_size=1)(image_pool)\n",
    "    image_pool = UpSampling2D(size=(H // image_pool.shape[1], W // image_pool.shape[2]),\n",
    "                              )(image_pool)\n",
    "\n",
    "    # Atrous Operaions using dilation\n",
    "    conv_1 = ConvBlock(kernel_size=1, dilation_rate=1)(X)\n",
    "    conv_6 = ConvBlock(kernel_size=3, dilation_rate=6)(X)\n",
    "    conv_12 = ConvBlock(kernel_size=3, dilation_rate=12)(X)\n",
    "    conv_18 = ConvBlock(kernel_size=3, dilation_rate=18)(X)\n",
    "\n",
    "    # Combine All\n",
    "    combined = Concatenate()([image_pool, conv_1, conv_6, conv_12, conv_18])\n",
    "    processed = ConvBlock(kernel_size=1)(combined)\n",
    "\n",
    "    # Final Output\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8):\n",
    "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "\n",
    "    return cbam_feature\n",
    "\n",
    "\n",
    "# improved cbam block for remote sensing\n",
    "\n",
    "def cbam_block_improved(cbam_feature, ratio=8):\n",
    "    cbam_channel = channel_attention(cbam_feature, ratio)\n",
    "    cbam_spatial = spatial_attention(cbam_feature)\n",
    "    result1 = multiply([cbam_channel, cbam_spatial])  # was multiply previously and performance was around 92.4\n",
    "    result2 = cbam_block(cbam_feature, ratio)\n",
    "    # combine both types of information\n",
    "    cbam_feature = Add()([result1, result2])  # previously it was  Add()\n",
    "    return cbam_feature\n",
    "\n",
    "\n",
    "# new attention improved\n",
    "def cbam_block_improved_new(cbam_feature, ratio=8):\n",
    "    cbam_channel = channel_attention(cbam_feature, ratio)\n",
    "    cbam_spatial = spatial_attention(cbam_feature)\n",
    "    result1 = multiply([cbam_channel, cbam_spatial])\n",
    "    result2 = cbam_block(cbam_feature, ratio)\n",
    "    # combine both types of information\n",
    "    cbam_feature = Concatenate()([result1, result2,cbam_feature])  # previously it was  Add()\n",
    "    res1 = Conv2D(filters=256, kernel_size=1, activation='relu', padding='same')(cbam_feature)\n",
    "    # res1 = BatchNormalization()(res1)\n",
    "    return res1\n",
    "\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    input_feature = Conv2D(256, (1, 1), activation='relu')(input_feature)\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    shared_layer_one = Dense(channel // ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    # print(cbam_feature.shape)\n",
    "    # print(input_feature.shape)\n",
    "    # element wise application\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    input_feature = Conv2D(256, (1, 1), activation='relu')(input_feature)\n",
    "    kernel_size = 7\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2, 3, 1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=1,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          use_bias=False)(concat)\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input, ratio=16):\n",
    "    ''' Create a channel-wise squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "    Returns: a keras tensor\n",
    "    References\n",
    "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init.shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    # if K.image_data_format() == 'channels_first':\n",
    "    #     se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    print(init.shape)\n",
    "    print(se.shape)\n",
    "    x = multiply([init, se])\n",
    "    return x\n",
    "\n",
    "\n",
    "def spatial_squeeze_excite_block(input):\n",
    "    ''' Create a spatial squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "    Returns: a keras tensor\n",
    "    References\n",
    "    -   [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)\n",
    "    '''\n",
    "\n",
    "    se = Conv2D(1, (1, 1), activation='sigmoid', use_bias=False,\n",
    "                kernel_initializer='he_normal')(input)\n",
    "\n",
    "    x = multiply([input, se])\n",
    "    return x\n",
    "\n",
    "\n",
    "# Adaptive ECA module\n",
    "def eca_module(inputs, gamma=2, b=1):\n",
    "    x = inputs\n",
    "    t = int(abs((K.int_shape(x)[3] * gamma) // b))\n",
    "    k = t if t % 2 else t + 1\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, x.shape[1]))(x)\n",
    "    x = Conv2D(1, (k, k), padding='same', kernel_initializer='he_normal', use_bias=False)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = multiply([inputs, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def EARCM_improved_TGRS(input_tensor):\n",
    "    lev_1 = Conv2D(256, (1, 1), padding='same')(input_tensor)  # 1x1 convolution and reduce channel\n",
    "    lev_2 = Conv2D(256, (2, 2), padding='same')(input_tensor)  # 1x1 convolution and reduce channel\n",
    "    lev_3 = Conv2D(256, (3, 3), padding='same')(input_tensor)  # 3x3 convolution and reduce channel\n",
    "    lev_4 = Conv2D(256, (4, 4), padding='same')(input_tensor)  # 4x4 convolution and reduce channel\n",
    "    lev_5 = Conv2D(256, (5, 5), padding='same')(input_tensor)  # 5x5 convolution and reduce channel\n",
    "\n",
    "    # CBAM modified block\n",
    "    cbam_imp = cbam_block_improved(input_tensor)\n",
    "    # proposed approach is concat\n",
    "    res1 = Concatenate()(\n",
    "        [lev_1, lev_3, lev_5, cbam_imp])  # prev, [lev_1, lev_3, lev_5]===94.40%\n",
    "\n",
    "    # convolution 1 by 1 for the fusion\n",
    "    conv = conv1by1(res1)\n",
    "\n",
    "    # # eca for the selection of interesting regions after fusion\n",
    "    #eca = eca_module(conv)  # eca worked well! acc: 94.40%\n",
    "    eca= channel_spatial_squeeze_excite(conv)\n",
    "    # bn=BatchNormalization()(eca)\n",
    "    return eca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_crop_img(path, grayscale=False, color_mode='rgb', target_size=None,\n",
    "                      interpolation='nearest'):\n",
    "    \"\"\"Wraps keras_preprocessing.image.utils.loag_img() and adds cropping.\n",
    "    Cropping method enumarated in interpolation\n",
    "    # Arguments\n",
    "        path: Path to image file.\n",
    "        color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "            The desired image format.\n",
    "        target_size: Either `None` (default to original size)\n",
    "            or tuple of ints `(img_height, img_width)`.\n",
    "        interpolation: Interpolation and crop methods used to resample and crop the image\n",
    "            if the target size is different from that of the loaded image.\n",
    "            Methods are delimited by \":\" where first part is interpolation and second is crop\n",
    "            e.g. \"lanczos:random\".\n",
    "            Supported interpolation methods are \"nearest\", \"bilinear\", \"bicubic\", \"lanczos\",\n",
    "            \"box\", \"hamming\" By default, \"nearest\" is used.\n",
    "            Supported crop methods are \"none\", \"center\", \"random\".\n",
    "    # Returns\n",
    "        A PIL Image instance.\n",
    "    # Raises\n",
    "        ImportError: if PIL is not available.\n",
    "        ValueError: if interpolation method is not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    # Decode interpolation string. Allowed Crop methods: none, center, random\n",
    "    interpolation, crop = interpolation.split(\":\") if \":\" in interpolation else (interpolation, \"none\")\n",
    "\n",
    "    if crop == \"none\":\n",
    "        return keras_preprocessing.image.utils.load_img(path,\n",
    "                                                        grayscale=grayscale,\n",
    "                                                        color_mode=color_mode,\n",
    "                                                        target_size=target_size,\n",
    "                                                        interpolation=interpolation)\n",
    "\n",
    "    # Load original size image using Keras\n",
    "    img = keras_preprocessing.image.utils.load_img(path,\n",
    "                                                   grayscale=grayscale,\n",
    "                                                   color_mode=color_mode,\n",
    "                                                   target_size=None,\n",
    "                                                   interpolation=interpolation)\n",
    "\n",
    "    # Crop fraction of total image\n",
    "    crop_fraction = 0.875\n",
    "    target_width = target_size[1]\n",
    "    target_height = target_size[0]\n",
    "\n",
    "    if target_size is not None:\n",
    "        if img.size != (target_width, target_height):\n",
    "\n",
    "            if crop not in [\"center\", \"random\"]:\n",
    "                raise ValueError('Invalid crop method {} specified.', crop)\n",
    "\n",
    "            if interpolation not in keras_preprocessing.image.utils._PIL_INTERPOLATION_METHODS:\n",
    "                raise ValueError(\n",
    "                    'Invalid interpolation method {} specified. Supported '\n",
    "                    'methods are {}'.format(interpolation,\n",
    "                                            \", \".join(\n",
    "                                                keras_preprocessing.image.utils._PIL_INTERPOLATION_METHODS.keys())))\n",
    "\n",
    "            resample = keras_preprocessing.image.utils._PIL_INTERPOLATION_METHODS[interpolation]\n",
    "\n",
    "            width, height = img.size\n",
    "\n",
    "            # Resize keeping aspect ratio\n",
    "            # result shold be no smaller than the targer size, include crop fraction overhead\n",
    "            target_size_before_crop = (target_width / crop_fraction, target_height / crop_fraction)\n",
    "            ratio = max(target_size_before_crop[0] / width, target_size_before_crop[1] / height)\n",
    "            target_size_before_crop_keep_ratio = int(width * ratio), int(height * ratio)\n",
    "            img = img.resize(target_size_before_crop_keep_ratio, resample=resample)\n",
    "\n",
    "            width, height = img.size\n",
    "\n",
    "            if crop == \"center\":\n",
    "                left_corner = int(round(width / 2)) - int(round(target_width / 2))\n",
    "                top_corner = int(round(height / 2)) - int(round(target_height / 2))\n",
    "                return img.crop((left_corner, top_corner, left_corner + target_width, top_corner + target_height))\n",
    "            elif crop == \"random\":\n",
    "                left_shift = random.randint(0, int((width - target_width)))\n",
    "                down_shift = random.randint(0, int((height - target_height)))\n",
    "                return img.crop((left_shift, down_shift, target_width + left_shift, target_height + down_shift))\n",
    "\n",
    "    return img\n",
    "\n",
    "# Monkey patch\n",
    "keras_preprocessing.image.iterator.load_img = load_and_crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_spatial_squeeze_excite(input, ratio=16):\n",
    "    ''' Create a spatial squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "    Returns: a keras tensor\n",
    "    References\n",
    "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "    -   [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)\n",
    "    '''\n",
    "\n",
    "    cse = squeeze_excite_block(input, ratio)\n",
    "    sse = spatial_squeeze_excite_block(input)\n",
    "\n",
    "    x = add([cse, sse])\n",
    "    return x\n",
    "\n",
    "\n",
    "# Change the number of filters to 1280 for more information or keep 2688 as it is with 1 by 1 convolution,previously 1024\n",
    "def conv1by1(input_tensor):\n",
    "    tensor = Conv2D(256, (1, 1), activation='relu')(input_tensor)  # 256-D provides around 94% acc.\n",
    "    # tensor = squeeze_excite_block(tensor)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def sequence_layer(input):\n",
    "    print(input.shape)\n",
    "    # input= conv1by1(input)\n",
    "    units = input.shape[1] * input.shape[2]\n",
    "    reshape = Reshape((units, input.shape[3]))(input)\n",
    "    lstm_layer = LSTM(49, input_shape=(units, input.shape[3]), return_sequences=True)(reshape)\n",
    "    flatten = Flatten()(lstm_layer)\n",
    "    return flatten\n",
    "\n",
    "def multi_scale_msafeb(input_tensor, ratio=4):\n",
    "    print(input_tensor.shape)\n",
    "    filter = input_tensor.shape[3]\n",
    "    # p0=Modules.AtrousSpatialPyramidPooling(input_tensor), dilation=4, and groups=10, provided 93.80%\n",
    "    pool1 = Conv2D(filters=filter / ratio, kernel_size=1, activation='relu', padding='same', dilation_rate=4,\n",
    "                   groups=8)(\n",
    "        input_tensor)  # previously 12 groups, could try 16 as well for more groups\n",
    "    pool1_ = GlobalAveragePooling2D()(pool1)\n",
    "    p1 = Modules.AtrousSpatialPyramidPooling(pool1)\n",
    "    # p1 =eca_module(pool1)\n",
    "\n",
    "    pool2 = Conv2D(filters=filter / ratio, kernel_size=3, activation='relu', padding='same', dilation_rate=4,\n",
    "                   groups=8)(\n",
    "        input_tensor)\n",
    "    pool2_ = GlobalAveragePooling2D()(pool2)\n",
    "    p2 = atrouspp.AtrousSpatialPyramidPooling(pool2)\n",
    "    # p2=eca_module(pool2)\n",
    "\n",
    "    pool3 = Conv2D(filters=filter / ratio, kernel_size=5, activation='relu', padding='same', dilation_rate=4,\n",
    "                   groups=8)(\n",
    "        input_tensor)\n",
    "    # pool3 = MaxPooling2D((3, 3))(res1)\n",
    "    pool3_ = GlobalAveragePooling2D()(pool3)\n",
    "    p3 = atrouspp.AtrousSpatialPyramidPooling(pool3)\n",
    "    # p3=eca_module(pool3)\n",
    "\n",
    "    # horizontal/vertical sigmoid feature extraction\n",
    "    hrv1 = multi_scale_hrv_pooling(\n",
    "        pool1)  # gap based approach with pool1 provided 94.70+ performance on the first fold\n",
    "\n",
    "    conv = concatenate([p1, p2, p3, input_tensor,hrv1])\n",
    "\n",
    "    #conv = conv1by1(conv)\n",
    "\n",
    "    earcm = EARCM_improved_TGRS(conv)  # our own attention block\n",
    "\n",
    "    bn = BatchNormalization()(earcm)\n",
    "    return bn, pool1_, pool2_, pool3_\n",
    "\n",
    "\n",
    "def rotation_invariant(input_tensor):\n",
    "    # rotation\n",
    "    o = input_tensor\n",
    "    r1 = tf.image.rot90(input_tensor, k=1)\n",
    "    # r2 = tf.image.rot90(input_tensor, k=2)\n",
    "    # r3 = tf.image.rot90(input_tensor, k=3)\n",
    "\n",
    "    # msafeb\n",
    "    o_m, o_p1, o_p2, o_p3 = multi_scale_msafeb(o)\n",
    "    r1_m, r1_p1, r1_p2, r1_p3 = multi_scale_msafeb(r1)\n",
    "    # r2_m, r2_p1, r2_p2, r2_p3 = multi_scale_msafeb(r2)\n",
    "    # r3_m, r3_p1, r3_p2, r3_p3 = multi_scale_msafeb(r3)\n",
    "\n",
    "    # fusion operation\n",
    "    # m_avg = average([o_m, r1_m])\n",
    "    # p1_avg =\n",
    "    # p2_avg = average([o_p2, r1_p2])\n",
    "    # p3_avg = average([o_p3, r1_p3])\n",
    "\n",
    "    return average([o_m, r1_m]), average([o_p1, r1_p1]), average([o_p2, r1_p2]), \\\n",
    "        average([o_p3, r1_p3])\n",
    "\n",
    "\n",
    "# proposed hrv-based spatial and channel attention\n",
    "def hrv_spatial_channel(input_tensor):\n",
    "    spatial = multi_scale_hrv_pooling(input_tensor)\n",
    "    channel = eca_module(input_tensor)\n",
    "    combined = add([spatial, channel])\n",
    "    return combined\n",
    "\n",
    "\n",
    "def MSFEB(input_tensor, ratio=4):\n",
    "    print(input_tensor.shape)\n",
    "    filter = input_tensor.shape[3]\n",
    "    # p0=Modules.AtrousSpatialPyramidPooling(input_tensor), dilation=4, and groups=10, provided 93.80%\n",
    "    pool1 = Conv2D(filters=filter / ratio, kernel_size=1, activation='relu', padding='same', dilation_rate=4,\n",
    "                   groups=8)(\n",
    "        input_tensor)  # previously 12 groups, could try 16 as well for more groups\n",
    "    pool1_ = GlobalAveragePooling2D()(pool1)\n",
    "    p1 = Modules.AtrousSpatialPyramidPooling(pool1)\n",
    "\n",
    "    # p1 =eca_module(pool1)\n",
    "\n",
    "    pool2 = Conv2D(filters=filter / ratio, kernel_size=3, activation='relu', padding='same', dilation_rate=4,\n",
    "                   groups=8)(\n",
    "        input_tensor)\n",
    "    pool2_ = GlobalAveragePooling2D()(pool2)\n",
    "    p2 = atrouspp.AtrousSpatialPyramidPooling(pool2)\n",
    "\n",
    "    # p2=eca_module(pool2)\n",
    "\n",
    "    pool3 = Conv2D(filters=filter / ratio, kernel_size=5, activation='relu', padding='same', dilation_rate=4,\n",
    "                   groups=8)(\n",
    "        input_tensor)\n",
    "    # pool3 = MaxPooling2D((3, 3))(res1)\n",
    "    pool3_ = GlobalAveragePooling2D()(pool3)\n",
    "    p3 = atrouspp.AtrousSpatialPyramidPooling(pool3)\n",
    "\n",
    "    # p3=eca_module(pool3)\n",
    "\n",
    "    concat = concatenate([p1, p2, p3, input_tensor])\n",
    "\n",
    "    conv = conv1by1(concat)\n",
    "\n",
    "    earcm = EACRM(conv)  # our own attention block\n",
    "    # earcm = cbam_block_improved_new(conv)\n",
    "    # se_attention = squeeze_excite_block(concat)\n",
    "    # layer_in = SeparableConv2D(filters=filter / ratio, kernel_size=(3, 3), padding='same', activation='relu')(\n",
    "    #     se_attention)  # depth separable convolution\n",
    "    bn = BatchNormalization()(earcm)\n",
    "    # gap = GlobalAveragePooling2D()(bn)\n",
    "    return bn, pool1_, pool2_, pool3_\n",
    "\n",
    "\n",
    "# horizontal pooling\n",
    "def hpool(k, x, tsnr):\n",
    "    hp = AveragePooling2D(pool_size=(x, k), padding='same')(tsnr)  # max pooling along ineffective\n",
    "    return hp\n",
    "\n",
    "\n",
    "def hpool_max(k, x, tsnr):\n",
    "    hp = MaxPooling2D(pool_size=(x, k), padding='same')(tsnr)  # max pooling along ineffective\n",
    "    return hp\n",
    "\n",
    "\n",
    "# vertical pooling\n",
    "def vpool(k, x, tsnr):\n",
    "    vp = AveragePooling2D(pool_size=(x, k), padding='same')(tsnr)  # max pooling along ineffective\n",
    "    return vp\n",
    "\n",
    "\n",
    "def vpool_max(k, x, tsnr):\n",
    "    vp = MaxPooling2D(pool_size=(x, k), padding='same')(tsnr)  # max pooling along ineffective\n",
    "    return vp\n",
    "\n",
    "\n",
    "# combination and use attention to capture salient information\n",
    "def hvpool(hp, vp, tnsr):\n",
    "    # matrix multiplication\n",
    "    print(hp)\n",
    "    print(vp)\n",
    "    # print(tnsr)\n",
    "    mul = multiply([vp, hp])\n",
    "    # attention layer EARCM: TODO\n",
    "    x = Activation('sigmoid')(mul)\n",
    "    # x = multiply([tnsr, x])\n",
    "    # mul_ = EACRM(mul)\n",
    "    return x\n",
    "\n",
    "\n",
    "def multi_scale_hrv_pooling(tensor):\n",
    "    scales = [1]\n",
    "    tensors = []\n",
    "    # for i in range(0, len(scales)):\n",
    "    vp = vpool(tensor.shape[1], 1, tensor)\n",
    "    hp = hpool(1, tensor.shape[2], tensor)\n",
    "    cmb = hvpool(hp, vp, tensor)\n",
    "    # tensors.append(cmb)\n",
    "    return cmb\n",
    "\n",
    "\n",
    "def multi_scale_hrv_mx_pooling(tensor):\n",
    "    scales = [1]\n",
    "    tensors = []\n",
    "    # for i in range(0, len(scales)):\n",
    "    vp = vpool_max(tensor.shape[1], 1, tensor)\n",
    "    hp = hpool_max(1, tensor.shape[2], tensor)\n",
    "    cmb = hvpool(hp, vp, tensor)\n",
    "    # tensors.append(cmb)\n",
    "    return cmb\n",
    "\n",
    "\n",
    "def multi_scale_hrv_mixed_pooling(tensor):\n",
    "    vp = multi_scale_hrv_pooling(tensor)\n",
    "    hp = multi_scale_hrv_mx_pooling(tensor)\n",
    "    cmb = add([vp, hp])\n",
    "    return cmb\n",
    "\n",
    "\n",
    "# hrv\n",
    "def horizontal(input_tensor, size):\n",
    "    h = AveragePooling2D(pool_size=(size, input_tensor.shape[1]), strides=1)(input_tensor)\n",
    "    return GlobalAveragePooling2D()(h)\n",
    "\n",
    "\n",
    "def vertical(input_tensor, size):\n",
    "    v = AveragePooling2D(pool_size=(input_tensor.shape[2], size), strides=1)(input_tensor)\n",
    "    return GlobalAveragePooling2D()(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning decay rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.4  # in 0.5 it provided an accuracy of 80%+\n",
    "    epochs_drop = 4.0  # 5.0 gives an optimal epochs_drop\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "# single level\n",
    "def multi_scale_aspp_hrv(model, classes):\n",
    "    m_ = model.output\n",
    "\n",
    "    # hrv input\n",
    "    # m_= Modules.multi_scale_hrv_pooling(m_)\n",
    "    m, p1_, p2_, p3_ = multi_scale_msafeb(m_)\n",
    "    #m, p1_, p2_, p3_ = rotation_invariant(m_)\n",
    "\n",
    "    m = GlobalAveragePooling2D()(m)\n",
    "\n",
    "    c = concatenate([m, p1_, p2_, p3_])  # [m, p1_, p2_, p3_]>>94.40+ for the fold 1\n",
    "    # # c = BatchNormalization()(m1)\n",
    "    c = Dropout(0.2)(c)\n",
    "    outputs = Dense(classes, activation='softmax')(c)\n",
    "    prop = Model(model.input, outputs)\n",
    "    return prop\n",
    "\n",
    "\n",
    "def fine_tune(model, classes):\n",
    "    m_ = model.output\n",
    "    m = GlobalAveragePooling2D()(m_)\n",
    "    c = Dropout(0.2)(m)\n",
    "    outputs = Dense(classes, activation='softmax')(c)\n",
    "    m_ = Model(model.input, outputs)\n",
    "    return m_\n",
    "\n",
    "\n",
    "def train_ml(model, train_batches, valid_batches, classes):\n",
    "    # m = custom_resnet50(model, classes)\n",
    "    m = multi_scale_aspp_hrv(model, classes)\n",
    "    # m = fine_tune(model, classes)\n",
    "    # m=ensemble(classes)\n",
    "    # m=model\n",
    "#     print(m.summary())\n",
    "    # m = model\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.0003  # for one step\n",
    "    m.compile(loss='categorical_crossentropy',  # for multiclass use categorical_crossentropy\n",
    "              # optimizer=optimizers.SGD(lr=LEARNING_RATE,momentum=0.9),\n",
    "              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "              #  optimizer=optimizers.Adam(lr_schedule),\n",
    "              metrics=['acc'])\n",
    "\n",
    "    # print(model.summary())\n",
    "    # learning schedule callback\n",
    "    # es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    mcp_save = ModelCheckpoint('Fold' + str(i) + '_step1.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    callbacks_list = [lrate]\n",
    "\n",
    "    STEP_SIZE_TRAIN = train_batches.n // train_batches.batch_size\n",
    "    STEP_SIZE_VALID = valid_batches.n // valid_batches.batch_size\n",
    "    # lr_decay = LearningRateScheduler(schedule=lambda epoch: LEARNING_RATE * (0.9 ** epoch))\n",
    "    # callbacks_list=[es]\n",
    "    m.fit_generator(train_batches,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    callbacks=callbacks_list\n",
    "                    )\n",
    "\n",
    "    x = m.evaluate_generator(valid_batches,\n",
    "                             steps=np.ceil(len(valid_batches)),\n",
    "                             use_multiprocessing=False,\n",
    "                             verbose=1,\n",
    "                             workers=1,\n",
    "                             )\n",
    "    #  print('Testing time:' + str(time.clock() - test_s_time) + 'secs.')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/niecongchong/DANet-keras/blob/master/layers/attention.py\n",
    "# https://arxiv.org/pdf/1809.02983.pdf\n",
    "from tensorflow.keras.layers import Activation, Conv2D\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class PAM(Layer):\n",
    "    def __init__(self,\n",
    "                 gamma_initializer=tf.zeros_initializer(),\n",
    "                 gamma_regularizer=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(PAM, self).__init__(**kwargs)\n",
    "        self.gamma_initializer = gamma_initializer\n",
    "        self.gamma_regularizer = gamma_regularizer\n",
    "        self.gamma_constraint = gamma_constraint\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(shape=(1, ),\n",
    "                                     initializer=self.gamma_initializer,\n",
    "                                     name='gamma',\n",
    "                                     regularizer=self.gamma_regularizer,\n",
    "                                     constraint=self.gamma_constraint)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def call(self, input):\n",
    "        input_shape = input.get_shape().as_list()\n",
    "        _, h, w, filters = input_shape\n",
    "\n",
    "        b = Conv2D(filters // 8, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "        c = Conv2D(filters // 8, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "        d = Conv2D(filters, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "\n",
    "        vec_b = K.reshape(b, (-1, h * w, filters // 8))\n",
    "        vec_cT = tf.transpose(K.reshape(c, (-1, h * w, filters // 8)), (0, 2, 1))\n",
    "        bcT = K.batch_dot(vec_b, vec_cT)\n",
    "        softmax_bcT = Activation('softmax')(bcT)\n",
    "        vec_d = K.reshape(d, (-1, h * w, filters))\n",
    "        bcTd = K.batch_dot(softmax_bcT, vec_d)\n",
    "        bcTd = K.reshape(bcTd, (-1, h, w, filters))\n",
    "\n",
    "        out = self.gamma*bcTd + input\n",
    "        return out\n",
    "\n",
    "\n",
    "class CAM(Layer):\n",
    "    def __init__(self,\n",
    "                 gamma_initializer=tf.zeros_initializer(),\n",
    "                 gamma_regularizer=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(CAM, self).__init__(**kwargs)\n",
    "        self.gamma_initializer = gamma_initializer\n",
    "        self.gamma_regularizer = gamma_regularizer\n",
    "        self.gamma_constraint = gamma_constraint\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(shape=(1, ),\n",
    "                                     initializer=self.gamma_initializer,\n",
    "                                     name='gamma',\n",
    "                                     regularizer=self.gamma_regularizer,\n",
    "                                     constraint=self.gamma_constraint)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def call(self, input):\n",
    "        input_shape = input.get_shape().as_list()\n",
    "        _, h, w, filters = input_shape\n",
    "\n",
    "        vec_a = K.reshape(input, (-1, h * w, filters))\n",
    "        vec_aT = tf.transpose(vec_a, (0, 2, 1))\n",
    "        aTa = K.batch_dot(vec_aT, vec_a)\n",
    "        softmax_aTa = Activation('softmax')(aTa)\n",
    "        aaTa = K.batch_dot(vec_a, softmax_aTa)\n",
    "        aaTa = K.reshape(aaTa, (-1, h, w, filters))\n",
    "\n",
    "        out = self.gamma*aaTa + input\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAM_PAM(input_tensor):\n",
    "    pam = PAM()(input_tensor)\n",
    "    pam = Conv2D(512, 3, padding='same', use_bias=False, kernel_initializer='he_normal')(pam)\n",
    "    pam = BatchNormalization(axis=3)(pam)\n",
    "    pam = Activation('relu')(pam)\n",
    "    pam = Dropout(0.5)(pam)\n",
    "    pam = Conv2D(512, 3, padding='same', use_bias=False, kernel_initializer='he_normal')(pam)\n",
    "\n",
    "    cam = CAM()(input_tensor)\n",
    "    cam = Conv2D(512, 3, padding='same', use_bias=False, kernel_initializer='he_normal')(cam)\n",
    "    cam = BatchNormalization(axis=3)(cam)\n",
    "    cam = Activation('relu')(cam)\n",
    "    cam = Dropout(0.5)(cam)\n",
    "    cam = Conv2D(512, 3, padding='same', use_bias=False, kernel_initializer='he_normal')(cam)\n",
    "\n",
    "    feature_sum = add([pam, cam])\n",
    "    return feature_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def BAM(inputs,reduction_ratio=16, dilation_value=4, reuse=None, scope='BAM'):\n",
    "#     with tf.variable_scope(scope, reuse=reuse):\n",
    "#         with tf.compat.v1.keras.backend.name_scope(scope):\n",
    "#             with tf.compat.v1.keras.backend.name_scope('BAM'):\n",
    "    input_channel = inputs.get_shape().as_list()[-1]\n",
    "    num_squeeze = input_channel // reduction_ratio\n",
    "\n",
    "    # Channel attention\n",
    "    gap = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "    channel = layers.Dense(num_squeeze, activation=None, kernel_initializer='glorot_uniform',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.0005))(gap)\n",
    "    channel = layers.Dense(input_channel, activation=None, kernel_initializer='glorot_uniform',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n",
    "                           )(channel)\n",
    "    channel = layers.BatchNormalization()(channel)\n",
    "\n",
    "    # Spatial attention\n",
    "    spatial = layers.Conv2D(num_squeeze, kernel_size=1, padding='same', activation=None,\n",
    "                            )(inputs)\n",
    "    spatial = layers.Conv2D(num_squeeze, kernel_size=3, padding='same', activation=None,\n",
    "                            dilation_rate=dilation_value)(spatial)\n",
    "    spatial = layers.Conv2D(num_squeeze, kernel_size=3, padding='same', activation=None,\n",
    "                            dilation_rate=dilation_value)(spatial)\n",
    "    spatial = layers.Conv2D(1, kernel_size=1, padding='same', activation=None,\n",
    "                            )(spatial)\n",
    "    spatial = layers.BatchNormalization()(spatial)\n",
    "\n",
    "    # Combined two attention branches\n",
    "    combined = tf.sigmoid(channel + spatial)\n",
    "\n",
    "    output = inputs + inputs * combined\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed algorithm for mid-level feature extraction\n",
    "def EACRM(input_tensor):\n",
    "    lev_1 = Conv2D(256, (1, 1))(input_tensor)  # 1x1 convolution and reduce channel\n",
    "    # print(lev_1.shape)\n",
    "    lev_2 = Conv2D(256, (3, 3))(input_tensor)  # 3x3 convolution and reduce channel\n",
    "    # lev_2= GlobalAveragePooling2D()(lev_2)\n",
    "    # print(lev_2.shape)\n",
    "    # Used attention modules\n",
    "    # CBAM--cbam_block()\n",
    "    # Dual--CAM_PAM()\n",
    "    # Channel SE--channel_spatial_squeeze_excite()\n",
    "    # SE--squeeze_excite_block()\n",
    "    lev_3 = CAM_PAM(input_tensor)  # Change here for the evaluation of each attention\n",
    "    # print(lev_3.shape)\n",
    "    # res1 = multiply([lev_1, lev_3])\n",
    "    # proposed approach is concat\n",
    "    res1 = Concatenate()(\n",
    "        [lev_1, lev_3])\n",
    "    # res1 = Add()(\n",
    "    #     [lev_1, lev_3])\n",
    "    return res1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_resnet50(model, classes):\n",
    "    invert11_ = model.get_layer('conv2_block3_out').output\n",
    "    invert1 = model.get_layer('conv3_block4_out').output\n",
    "    invert2 = model.get_layer('conv4_block6_out').output\n",
    "    invert3 = model.get_layer('conv5_block3_out').output\n",
    "\n",
    "    invert11_ = EACRM(invert11_)\n",
    "    invert1 = EACRM(invert1)\n",
    "    invert2 = EACRM(invert2)\n",
    "    invert3 = EACRM(invert3)\n",
    "\n",
    "    # ASPP\n",
    "    invert11_ = AtrousSpatialPyramidPooling(invert11_)\n",
    "    invert1 = AtrousSpatialPyramidPooling(invert1)\n",
    "    invert2 = AtrousSpatialPyramidPooling(invert2)\n",
    "    invert3 = AtrousSpatialPyramidPooling(invert3)\n",
    "\n",
    "    # GAP\n",
    "    invert11_ = GlobalAveragePooling2D()(invert11_)\n",
    "    invert1_ = GlobalAveragePooling2D()(invert1)\n",
    "    invert2_ = GlobalAveragePooling2D()(invert2)\n",
    "    invert3_ = GlobalAveragePooling2D()(invert3)\n",
    "\n",
    "    # combine all of them\n",
    "    comb = concatenate([\n",
    "        invert11_,\n",
    "        invert1_,\n",
    "        invert2_,\n",
    "        invert3_\n",
    "    ])\n",
    "    # comb = BatchNormalization()(comb)  # added to normalize\n",
    "    dense = Dense(1024, activation='relu')(comb)  # reduced the 1024->768\n",
    "    dense = Dense(768, activation='relu')(dense)  # reduced the 1024->768\n",
    "    # softmax\n",
    "    output = Dense(classes, activation='softmax')(dense)\n",
    "    model = Model(inputs=model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_ml(model, train_batches, valid_batches, classes):\n",
    "    m = custom_resnet50(model, classes)\n",
    "#     print(m.summary())\n",
    "    # m=model\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.0003\n",
    "    m.compile(loss='categorical_crossentropy',  # for multiclass use categorical_crossentropy\n",
    "              # optimizer=optimizers.SGD(lr=LEARNING_RATE,momentum=0.9),\n",
    "              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "              #  optimizer=optimizers.Adam(lr_schedule),\n",
    "              metrics=['acc'])\n",
    "\n",
    "    # print(model.summary())\n",
    "    # learning schedule callback\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    callbacks_list = [lrate,es]\n",
    "\n",
    "    STEP_SIZE_TRAIN = train_batches.n // train_batches.batch_size\n",
    "    STEP_SIZE_VALID = valid_batches.n // valid_batches.batch_size\n",
    "    # lr_decay = LearningRateScheduler(schedule=lambda epoch: LEARNING_RATE * (0.9 ** epoch))\n",
    "    # callbacks_list=[es]\n",
    "    result = m.fit_generator(train_batches,\n",
    "                             steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                             validation_data=valid_batches,\n",
    "                             validation_steps=STEP_SIZE_VALID,\n",
    "                             epochs=NUM_EPOCHS,\n",
    "                             callbacks=callbacks_list\n",
    "                             )\n",
    "\n",
    "    x = m.evaluate_generator(valid_batches,\n",
    "                             steps=np.ceil(len(valid_batches)),\n",
    "                             use_multiprocessing=False,\n",
    "                             verbose=1,\n",
    "                             workers=1,\n",
    "                             )\n",
    "    #  print('Testing time:' + str(time.clock() - test_s_time) + 'secs.')\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "#     return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    acc = []\n",
    "    for i in range(0, 5):\n",
    "        print('Fold:' + str(i + 1))\n",
    "        print(\"*\" * 100)\n",
    "        model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "        model.trainable = True\n",
    "        # data load and train\n",
    "        # root_path = \"D://Jagannath_dai/AID_/2_8/\" + str(i + 1) + '/'\n",
    "        root_path = \"/data/gpfs/projects/punim2008/data/NWPU_/1_9/\" + str(i + 1) + '/'\n",
    "        DATASET_PATH = root_path + 'train'\n",
    "        test_dir = root_path + 'val'\n",
    "        # DATASET_PATH = root_path/train'\n",
    "        # test_dir = 'root_path/val'\n",
    "        IMAGE_SIZE = (224, 224)\n",
    "        data_list = os.listdir(DATASET_PATH)\n",
    "        # data_list = os.listdir('D:/COVID/four_classes/splits/f4/train')\n",
    "        # Delete some classes that may interfere\n",
    "        print(len(data_list))\n",
    "        NUM_CLASSES = len(data_list)\n",
    "        BATCH_SIZE = 16  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "\n",
    "        # Train datagen here is a preprocessor\n",
    "        train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                           # rotation_range=50,\n",
    "                                           # width_shift_range=0.2,\n",
    "                                           # height_shift_range=0.2,\n",
    "                                           # shear_range=0.25,\n",
    "                                           # zoom_range=0.1,\n",
    "                                           # channel_shift_range=20,\n",
    "                                           horizontal_flip=True,\n",
    "                                           # ertical_flip=True,\n",
    "                                           # validation_split=0.2,\n",
    "                                           # fill_mode='constant'\n",
    "                                           )\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "        train_batches = train_datagen.flow_from_directory(DATASET_PATH,\n",
    "                                                          target_size=IMAGE_SIZE,\n",
    "                                                          shuffle=True,\n",
    "                                                          interpolation='lanczos:random',  # <--------- random crop\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          # subset=\"training\",\n",
    "                                                          seed=42,\n",
    "                                                          class_mode=\"categorical\"\n",
    "                                                          # For multiclass use categorical n for binary use binary\n",
    "                                                          )\n",
    "\n",
    "        valid_batches = test_datagen.flow_from_directory(test_dir,\n",
    "                                                         target_size=IMAGE_SIZE,\n",
    "                                                         shuffle=True,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         # interpolation = 'lanczos:center', # <--------- center crop\n",
    "                                                         # subset=\"validation\",\n",
    "                                                         seed=42,\n",
    "                                                         class_mode=\"categorical\"\n",
    "                                                         # For multiclass use categorical n for binary use binary\n",
    "                                                         )\n",
    "        x = train_ml(model, train_batches, valid_batches, NUM_CLASSES)\n",
    "        print('Test loss:', x[0])\n",
    "        print('Test accuracy:', x[1])\n",
    "        acc.append(x[1])\n",
    "        del x\n",
    "        del model\n",
    "\n",
    "    # print the accuracy\n",
    "    print(acc)\n",
    "    a = np.array(acc)\n",
    "    print('The averaged accuracy is:\\n')\n",
    "    print(np.mean(a))\n",
    "    print('The std is: \\n')\n",
    "    print(np.std(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
